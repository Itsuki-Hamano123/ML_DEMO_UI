{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_model_GiNZA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyORcz13DgE1pXKMUgzEgUKC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Itsuki-Hamano123/ML_DEMO_UI/blob/master/gradio-app/text_model_GiNZA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cH_SzzRTwsh"
      },
      "source": [
        "%pip install -q transformers gradio"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAfS4y268dt9",
        "outputId": "c11cc305-9139-4ca9-ef4c-8bae30340fa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "source": [
        "%pip show tensorflow\n",
        "%pip show transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.3.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: h5py, termcolor, protobuf, opt-einsum, tensorboard, wrapt, wheel, grpcio, numpy, six, astunparse, tensorflow-estimator, scipy, gast, keras-preprocessing, google-pasta, absl-py\n",
            "Required-by: fancyimpute\n",
            "Name: transformers\n",
            "Version: 3.3.1\n",
            "Summary: State-of-the-art Natural Language Processing for TensorFlow 2.0 and PyTorch\n",
            "Home-page: https://github.com/huggingface/transformers\n",
            "Author: Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Sam Shleifer, Patrick von Platen, Sylvain Gugger, Google AI Language Team Authors, Open AI team Authors, Facebook AI Authors, Carnegie Mellon University Authors\n",
            "Author-email: thomas@huggingface.co\n",
            "License: Apache\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: dataclasses, packaging, tqdm, numpy, requests, sentencepiece, filelock, sacremoses, tokenizers, regex\n",
            "Required-by: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJa1fURt8nd3"
      },
      "source": [
        "### 形態素解析用GiNZA辞書のインストール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whzqEtXO8r9H",
        "outputId": "b6370b25-f896-4739-86ae-be285e7a523e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "%pip install -q ginza\n",
        "%pip show ginza\n",
        "\n",
        "import pkg_resources, imp\n",
        "imp.reload(pkg_resources)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: ginza\n",
            "Version: 4.0.5\n",
            "Summary: GiNZA, An Open Source Japanese NLP Library, based on Universal Dependencies\n",
            "Home-page: https://github.com/megagonlabs/ginza\n",
            "Author: Megagon Labs, Tokyo.\n",
            "Author-email: ginza@megagon.ai\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: spacy, ja-ginza, SudachiPy, SudachiDict-core\n",
            "Required-by: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'pkg_resources' from '/usr/local/lib/python3.6/dist-packages/pkg_resources/__init__.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKz9ljZ49Fzz",
        "outputId": "47802693-a4b1-4cfd-d50c-0528426c3bf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 971
        }
      },
      "source": [
        "# spacyとGiNZAの実行確認\n",
        "import spacy\n",
        "\n",
        "JA_DICT = 'ja_ginza' #@param {type:'string'}\n",
        "parser = spacy.load(JA_DICT)\n",
        "sample_text = \"8月3日に放送された「中居正広の金曜日のスマイルたちへ」(TBS系)で、1日たった5分でぽっこりおなかを解消するというダイエット方法を紹介。キンタロー。のダイエットにも密着。\"\n",
        "\n",
        "res = parser(sample_text)\n",
        "for sent in res.sents:\n",
        "    for token in sent:\n",
        "        print(token.i, token.orth_, token.lemma_, token.pos_, token.tag_, token.dep_, token.head.i)\n",
        "    print('EOS')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 8 8 NUM 名詞-数詞 nummod 3\n",
            "1 月 月 NOUN 名詞-普通名詞-助数詞可能 compound 3\n",
            "2 3 3 NUM 名詞-数詞 nummod 3\n",
            "3 日 日 NOUN 接尾辞-名詞的-助数詞 obl 5\n",
            "4 に に ADP 助詞-格助詞 case 3\n",
            "5 放送 放送 VERB 名詞-普通名詞-サ変可能 acl 16\n",
            "6 さ する AUX 動詞-非自立可能 advcl 5\n",
            "7 れ れる AUX 助動詞 aux 5\n",
            "8 た た AUX 助動詞 aux 5\n",
            "9 「 「 PUNCT 補助記号-括弧開 punct 11\n",
            "10 中居 中居 PROPN 名詞-固有名詞-人名-姓 compound 11\n",
            "11 正広 正広 PROPN 名詞-固有名詞-人名-名 nmod 13\n",
            "12 の の ADP 助詞-格助詞 case 11\n",
            "13 金曜日 金曜日 NOUN 名詞-普通名詞-副詞可能 nmod 16\n",
            "14 の の ADP 助詞-格助詞 case 13\n",
            "15 スマイル スマイル NOUN 名詞-普通名詞-一般 compound 16\n",
            "16 たち たち NOUN 接尾辞-名詞的-一般 ROOT 16\n",
            "17 へ へ ADP 助詞-格助詞 case 16\n",
            "18 」 」 PUNCT 補助記号-括弧閉 punct 16\n",
            "EOS\n",
            "19 ( （ PUNCT 補助記号-括弧開 punct 21\n",
            "20 TBS TBS PROPN 名詞-固有名詞-一般 compound 21\n",
            "21 系 系 NOUN 接尾辞-名詞的-一般 nmod 40\n",
            "22 ) ) PUNCT 補助記号-括弧閉 punct 21\n",
            "23 で で ADP 助詞-格助詞 cop 21\n",
            "24 、 、 PUNCT 補助記号-読点 punct 21\n",
            "25 1 1 NUM 名詞-数詞 nummod 26\n",
            "26 日 日 NOUN 名詞-普通名詞-助数詞可能 nmod 29\n",
            "27 たった たった ADV 副詞 advmod 29\n",
            "28 5 5 NUM 名詞-数詞 nummod 29\n",
            "29 分 分 NOUN 名詞-普通名詞-助数詞可能 obl 33\n",
            "30 で で ADP 助詞-格助詞 case 29\n",
            "31 ぽっこりおなか ぽっこりおなか NOUN 名詞-普通名詞-一般 obj 33\n",
            "32 を を ADP 助詞-格助詞 case 31\n",
            "33 解消 解消 VERB 名詞-普通名詞-サ変可能 acl 38\n",
            "34 する する AUX 動詞-非自立可能 advcl 33\n",
            "35 と と ADP 助詞-格助詞 case 33\n",
            "36 いう いう VERB 動詞-一般 fixed 35\n",
            "37 ダイエット ダイエット NOUN 名詞-普通名詞-サ変可能 compound 38\n",
            "38 方法 方法 NOUN 名詞-普通名詞-一般 obj 40\n",
            "39 を を ADP 助詞-格助詞 case 38\n",
            "40 紹介 紹介 NOUN 名詞-普通名詞-サ変可能 ROOT 40\n",
            "41 。 。 PUNCT 補助記号-句点 punct 40\n",
            "EOS\n",
            "42 キンタロー キンタロー NOUN 名詞-普通名詞-一般 nmod 44\n",
            "43 。 。 PUNCT 補助記号-句点 punct 42\n",
            "44 の の ADP 助詞-格助詞 case 45\n",
            "45 ダイエット ダイエット NOUN 名詞-普通名詞-サ変可能 obl 48\n",
            "46 に に ADP 助詞-格助詞 case 45\n",
            "47 も も ADP 助詞-係助詞 case 45\n",
            "48 密着 密着 NOUN 名詞-普通名詞-サ変可能 ROOT 48\n",
            "49 。 。 PUNCT 補助記号-句点 punct 48\n",
            "EOS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOteu-W07B5v"
      },
      "source": [
        "def wakati_doc(parser, doc, join_key=' '):\n",
        "    '''文書データを形態素解析\n",
        "    \n",
        "    Parameters\n",
        "    -----\n",
        "    - parser: parser_obj\n",
        "    - doc : string\n",
        "        形態素解析対象の文章\n",
        "    - join_key : string (default:' ')\n",
        "        解析結果を結合する際の文字\n",
        "\n",
        "    Returns\n",
        "    -----\n",
        "    - result\n",
        "    '''\n",
        "    vocabes = []\n",
        "    result = parser(doc)\n",
        "    for sent in result.sents:\n",
        "        for token in sent:\n",
        "            top_pos = _pop_top_tag(tag_res=token.tag_)\n",
        "            if _is_allow_pos(token_pos=top_pos):\n",
        "                vocabes.append(token.lemma_)\n",
        "\n",
        "    result = join_key.join(vocabes)\n",
        "    return result\n",
        "\n",
        "\n",
        "def _pop_top_tag(tag_res):\n",
        "    '''\n",
        "    解析結果から先頭の品詞のみを抽出\n",
        "    '''\n",
        "    \n",
        "    def _split_tag(split_key='-'):\n",
        "        '''「品詞大項目-品詞中項目-品詞小項目」の形式を「-」で分割'''\n",
        "        return tag_res.split('-')\n",
        "\n",
        "    tags = []\n",
        "    tags = _split_tag()\n",
        "    tpo_tag = tags[0]\n",
        "    return tpo_tag\n",
        "\n",
        "\n",
        "def _is_allow_pos(token_pos):\n",
        "    '''\n",
        "    ストップワードに該当しない品詞の場合にTrueを返す\n",
        "\n",
        "    Parameters\n",
        "    -----\n",
        "    - token_pos : string\n",
        "        単語の品詞種別\n",
        "\n",
        "    Returns\n",
        "    -----\n",
        "    - allow_pos_flag : boolean\n",
        "    '''\n",
        "    allow_pos_flag = True\n",
        "    if token_pos in STOP_POS_LIST:\n",
        "        allow_pos_flag = False\n",
        "    return allow_pos_flag"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfQccpv2DMRN"
      },
      "source": [
        "## デモ用WebUIに必要なモジュールのインポート"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrnjXC6qT6Wk"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import gradio as gr\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelWithLMHead"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt64eULkbGEW"
      },
      "source": [
        "## 感情分析モデルのデモ用WebUI作成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzdtOHWYdhOS"
      },
      "source": [
        "モデルの選択などは全てpipelineに任せてみる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8alT_REW9ffw",
        "outputId": "e5d09d55-7c60-42b0-95d5-8b089c4d078e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        }
      },
      "source": [
        "%%time\n",
        "taskname = 'sentiment-analysis' #@param{type:'string'}\n",
        "nlp = pipeline(taskname)\n",
        "\n",
        "# 排除したいストップワードの品詞を設定\n",
        "STOP_POS_LIST = [\"助詞\", \"助動詞\", \"補助記号\"]\n",
        "\n",
        "# WebUIの入出力定義\n",
        "input_box = 'textbox'\n",
        "output_def = gr.outputs.Label(num_top_classes=1)\n",
        "\n",
        "\n",
        "# 入力を受け取ってから行う処理を定義\n",
        "def sensity_ana_nlp(input_text):\n",
        "  print(input_text)\n",
        "  wakati_text = wakati_doc(parser, input_text)\n",
        "  print(wakati_text)\n",
        "  result = nlp(wakati_text)[0]\n",
        "  return {result['label']: float(result['score'])}\n",
        "\n",
        "\n",
        "# Webページの起動\n",
        "gr.Interface(fn=sensity_ana_nlp, inputs=input_box, outputs=output_def).launch(debug=False)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "This share link will expire in 6 hours. If you need a permanent link, email support@gradio.app\n",
            "Running on External URL: https://12659.gradio.app\n",
            "Interface loading below...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"1000\"\n",
              "            height=\"500\"\n",
              "            src=\"https://12659.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f904751c0f0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.28 s, sys: 191 ms, total: 2.47 s\n",
            "Wall time: 7.52 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QrKTWwsXXz3"
      },
      "source": [
        "## 翻訳(ja→en)モデルのデモ用WebUI作成\n",
        "使用するモデル:[https://huggingface.co/Helsinki-NLP/opus-mt-ja-en](https://huggingface.co/Helsinki-NLP/opus-mt-ja-en)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBWknlupUecl",
        "outputId": "bbf7315e-1695-4179-d369-af95f3871b65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        }
      },
      "source": [
        "%%time\n",
        "# translation_ja_to_enが無いのでen_to_roを指定\n",
        "# モデルとトークナイザがあってれば動く模様\n",
        "taskname = 'translation_en_to_ro' #@param{type:'string'}\n",
        "specify_hugging_model = 'Helsinki-NLP/opus-mt-ja-en'#@param{type:'string'}\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(specify_hugging_model)\n",
        "model = AutoModelWithLMHead.from_pretrained(specify_hugging_model)\n",
        "nlp = pipeline(taskname, model=model, tokenizer=tokenizer)\n",
        "\n",
        "\n",
        "# WebUIの入出力定義\n",
        "input_box = 'textbox'\n",
        "output_box = 'textbox'\n",
        "\n",
        "\n",
        "# 入力を受け取ってから行う処理を定義\n",
        "def seq2seq_fn(input_text):\n",
        "  output_key = 'translation_text'\n",
        "  result = nlp([input_text])[0]\n",
        "  return result[output_key]\n",
        "\n",
        "\n",
        "# Webページの起動\n",
        "gr.Interface(fn=seq2seq_fn, inputs=input_box, outputs=output_box).launch(debug=False)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/modeling_auto.py:785: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "This share link will expire in 6 hours. If you need a permanent link, email support@gradio.app\n",
            "Running on External URL: https://56710.gradio.app\n",
            "Interface loading below...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"1000\"\n",
              "            height=\"500\"\n",
              "            src=\"https://56710.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f904bdbf0f0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5.31 s, sys: 791 ms, total: 6.1 s\n",
            "Wall time: 10.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}